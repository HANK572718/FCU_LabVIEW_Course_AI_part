{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Python Information ===\n",
      "Version: 3.9.13\n",
      "Bits: 64bit\n",
      "Executable Location: c:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe\n",
      "\n",
      "=== Torch Devices ===\n",
      "Torch Version: 2.4.0+cu124\n",
      "cpu\n",
      "\n",
      "=== Tensor Computation Time ===\n",
      "Time taken for tensor operations on cpu: 0.0262 seconds\n",
      "\n",
      "=== OpenVINO Information ===\n",
      "OpenVINO is installed.\n",
      "Available devices: ['CPU']\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def test_tensor_operations():\n",
    "    results = []  # 用於存儲所有結果的列表\n",
    "\n",
    "    # 1. 顯示 Python 版本資訊、位元數、位置\n",
    "    python_version = platform.python_version()\n",
    "    python_bits = platform.architecture()[0]\n",
    "    python_executable = sys.executable  # 取得 Python 執行檔位置\n",
    "\n",
    "    results.append(\"=== Python Information ===\")\n",
    "    results.append(f\"Version: {python_version}\")\n",
    "    results.append(f\"Bits: {python_bits}\")\n",
    "    results.append(f\"Executable Location: {python_executable}\\n\")\n",
    "\n",
    "    # 2. 顯示可用的 Torch devices\n",
    "    devices = [torch.device(\n",
    "        'cpu')] + [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "\n",
    "    results.append(\"=== Torch Devices ===\")\n",
    "    torch_vision = torch.__version__\n",
    "    results.append(f\"Torch Version: {torch_vision}\")\n",
    "    for device in devices:\n",
    "        results.append(str(device))\n",
    "\n",
    "    # 3. 測試每個設備的運行時間，以及進行複雜的 Tensor 操作\n",
    "    tensor_size = (1000, 1000)  # 調整 tensor 矩陣的大小\n",
    "    repetitions = 1  # 重複運行的次數\n",
    "    results.append(\"\\n=== Tensor Computation Time ===\")\n",
    "    for device in devices:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 創建隨機 tensor\n",
    "        tensor_a = torch.randn(tensor_size, device=device)\n",
    "        tensor_b = torch.randn(tensor_size, device=device)\n",
    "\n",
    "        # 進行多次操作以增加總耗時\n",
    "        for _ in range(repetitions):\n",
    "            tensor_sum = tensor_a + tensor_b  # Tensor 加法\n",
    "            tensor_product = tensor_a @ tensor_b  # 矩陣乘法\n",
    "            tensor_mean = tensor_sum.mean()  # 計算平均值\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        results.append(\n",
    "            f\"Time taken for tensor operations on {device}: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    # 4. 驗證 OpenVINO 安裝以及可用設備\n",
    "    try:\n",
    "        from openvino.runtime import Core  # 更新引用來匹配 openvino 的最近版本\n",
    "        ie = Core()\n",
    "        available_devices = ie.available_devices\n",
    "        results.append(\"\\n=== OpenVINO Information ===\")\n",
    "        results.append(\"OpenVINO is installed.\")\n",
    "        results.append(\"Available devices: \" + str(available_devices))\n",
    "    except ImportError:\n",
    "        results.append(\"\\n=== OpenVINO Information ===\")\n",
    "        results.append(\"OpenVINO is NOT installed.\")\n",
    "\n",
    "    # 將結果轉換為字串並返回\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "# 調用測試函數並打印結果\n",
    "if __name__ == \"__main__\":\n",
    "    output = test_tensor_operations()\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Count: 24\n",
      "Processor: Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "print(f\"CPU Count: {multiprocessing.cpu_count()}\")\n",
    "print(f\"Processor: {os.getenv('PROCESSOR_IDENTIFIER')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n",
      "GPU Count:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Available: \u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Count: \u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent GPU: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Name: \u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py:878\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU Available: \", torch.cuda.is_available())\n",
    "print(\"GPU Count: \", torch.cuda.device_count())\n",
    "print(\"Current GPU: \", torch.cuda.current_device())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
