{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Python Information ===\n",
      "Version: 3.9.13\n",
      "Bits: 64bit\n",
      "Executable Location: c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n",
      "\n",
      "=== Torch Devices ===\n",
      "Torch Version: 2.4.0+cu124\n",
      "cpu\n",
      "cuda:0\n",
      "\n",
      "=== Tensor Computation Time ===\n",
      "Time taken for tensor operations on cpu: 0.1294 seconds\n",
      "Time taken for tensor operations on cuda:0: 0.6139 seconds\n",
      "\n",
      "=== OpenVINO Information ===\n",
      "OpenVINO is installed.\n",
      "Available devices: ['CPU', 'GPU']\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "def test_tensor_operations():\n",
    "    results = []  # 用於存儲所有結果的列表\n",
    "\n",
    "    # 1. 顯示 Python 版本資訊、位元數、位置\n",
    "    python_version = platform.python_version()\n",
    "    python_bits = platform.architecture()[0]\n",
    "    python_executable = sys.executable  # 取得 Python 執行檔位置\n",
    "\n",
    "    results.append(\"=== Python Information ===\")\n",
    "    results.append(f\"Version: {python_version}\")\n",
    "    results.append(f\"Bits: {python_bits}\")\n",
    "    results.append(f\"Executable Location: {python_executable}\\n\")\n",
    "\n",
    "    # 2. 顯示可用的 Torch devices\n",
    "    devices = [torch.device(\n",
    "        'cpu')] + [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "\n",
    "    results.append(\"=== Torch Devices ===\")\n",
    "    torch_vision = torch.__version__\n",
    "    results.append(f\"Torch Version: {torch_vision}\")\n",
    "    for device in devices:\n",
    "        results.append(str(device))\n",
    "\n",
    "    # 3. 測試每個設備的運行時間，以及進行複雜的 Tensor 操作\n",
    "    tensor_size = (1000, 1000)  # 調整 tensor 矩陣的大小\n",
    "    repetitions = 1  # 重複運行的次數\n",
    "    results.append(\"\\n=== Tensor Computation Time ===\")\n",
    "    for device in devices:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 創建隨機 tensor\n",
    "        tensor_a = torch.randn(tensor_size, device=device)\n",
    "        tensor_b = torch.randn(tensor_size, device=device)\n",
    "\n",
    "        # 進行多次操作以增加總耗時\n",
    "        for _ in range(repetitions):\n",
    "            tensor_sum = tensor_a + tensor_b  # Tensor 加法\n",
    "            tensor_product = tensor_a @ tensor_b  # 矩陣乘法\n",
    "            tensor_mean = tensor_sum.mean()  # 計算平均值\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        results.append(\n",
    "            f\"Time taken for tensor operations on {device}: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    # 4. 驗證 OpenVINO 安裝以及可用設備\n",
    "    try:\n",
    "        from openvino.runtime import Core  # 更新引用來匹配 openvino 的最近版本\n",
    "        ie = Core()\n",
    "        available_devices = ie.available_devices\n",
    "        results.append(\"\\n=== OpenVINO Information ===\")\n",
    "        results.append(\"OpenVINO is installed.\")\n",
    "        results.append(\"Available devices: \" + str(available_devices))\n",
    "    except ImportError:\n",
    "        results.append(\"\\n=== OpenVINO Information ===\")\n",
    "        results.append(\"OpenVINO is NOT installed.\")\n",
    "\n",
    "    # 將結果轉換為字串並返回\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "# 調用測試函數並打印結果\n",
    "if __name__ == \"__main__\":\n",
    "    output = test_tensor_operations()\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Count: 16\n",
      "Processor: Intel64 Family 6 Model 186 Stepping 2, GenuineIntel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "print(f\"CPU Count: {multiprocessing.cpu_count()}\")\n",
    "print(f\"Processor: {os.getenv('PROCESSOR_IDENTIFIER')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Available: \u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n",
      "GPU Count:  1\n",
      "Current GPU:  0\n",
      "GPU Name:  NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU Available: \", torch.cuda.is_available())\n",
    "print(\"GPU Count: \", torch.cuda.device_count())\n",
    "print(\"Current GPU: \", torch.cuda.current_device())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 20 14:31:47 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.70                 Driver Version: 560.70         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P8              1W /   45W |     364MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     21832    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
